<div align="center">

# Health Data Science ML Pipeline  
### Powered by <br> Google AI Studio - <img src="https://upload.wikimedia.org/wikipedia/commons/b/b5/Google_ai_studio_logo.png" width="30"/> <br> Codex - <img src="https://upload.wikimedia.org/wikipedia/commons/c/c3/Openai.png" width="30"/>

[![Python](https://img.shields.io/badge/Python-3.11%2B-blue)]()
[![FastAPI](https://img.shields.io/badge/FastAPI-Backend-brightgreen)]()
[![React](https://img.shields.io/badge/Frontend-React-blueviolet)]()
[![scikit-learn](https://img.shields.io/badge/ML-scikit--learn-orange)]()

</div>

---

## Abstract

Atualmmente existem poucas ferramentas de modelagem preditiva acess√≠veis e amig√°veis para profissionais de sa√∫de de uma forma geral, ferramentas que permitam a este p√∫blico explorar de forma f√°cil e r√°pida **Machine Learning** (aprendizado de m√°quina) em seus pr√≥prios bancos de dados cl√≠nicos sem depender de fluxos de trabalho complexos.  

O **Health Data Science ML Pipeline** foi criado para preencher essa lacuna ‚Äî oferecendo um **workflow padronizado e automatizado** que guia o usu√°rio desde o upload do dataset at√© a gera√ß√£o dos resultados e interpreta√ß√£o dos modelos.  

Este projeto foi desenvolvido com assist√™ncia do **Google AI Studio** e do **Codex da OpenAI**, combinando automa√ß√£o em an√°lise de dados e suporte de IA para interpreta√ß√£o inteligente de resultados.

---

## Dataset Format (Input Specification)

Atualmente o programa exige datasets em formato **Excel (.xlsx)** conforme as regras abaixo:

- Primeira coluna: **ID exclusivo** (sem repeti√ß√µes).  
- √öltima coluna: **desfecho bin√°rio** (0 ou 1).  
- Colunas intermedi√°rias: **vari√°veis independentes num√©ricas**.  
  - Vari√°veis categ√≥ricas devem **preferencialmente** estar previamente convertidas em formato *one-hot-encoded*.  

Exemplo simplificado:

| ID | idade | pressao | glicose | sexo_M | sexo_F | desfecho |
|----|--------|----------|----------|---------|---------|-----------|
| 1 | 67 | 132 | 95 | 1 | 0 | 1 |
| 2 | 74 | 141 | 103 | 0 | 1 | 0 |

---

## Workflow Overview

O fluxo de trabalho foi desenhado para que o profissional de sa√∫de possa realizar an√°lises de forma **intuitiva e reproduz√≠vel**:

1. **Upload do banco de dados**  
   O usu√°rio envia um arquivo Excel conforme o formato exigido.

2. **An√°lise explorat√≥ria autom√°tica (EDA)**  
   O sistema exibe:
   - Porcentagem de desfecho (para checar balanceamento da amostra)  
   - Boxplots e histogramas para identificar outliers  
   - Tabelas de valores faltantes  
   - Correla√ß√µes e distribui√ß√µes das vari√°veis  

3. **Corre√ß√£o da base**  
   Com base nas sugest√µes autom√°ticas (missing, outliers, checagem pareada de multicolinearidade), √© poss√≠vel limpar o dataset via interface.

4. **Sele√ß√£o de modelos**  
   Usu√°rio escolhe os algoritmos a testar (Logistic Regression, Elastic Net, KNN, SVM, Random Forest, Gradient Boosting, XGBoost, LightGBM, CatBoost, Naive Bayes, Voting/Stacking ensembles e K-Means). Em cada fam√≠lia de modelo, o programa testa de forma sequencial diversos hiperpar√¢metros para encontrar aquele com melhor desempenho (baseado em √°rea sob a curva ROC e F1-score). O launcher instala todas as depend√™ncias necess√°rias (inclusive XGBoost, LightGBM e CatBoost) antes de abrir o navegador, garantindo que os boosters estejam prontos para uso; se voc√™ executar o backend manualmente fora do launcher, o sistema continuar√° exibindo mensagens claras caso alguma dessas bibliotecas n√£o esteja dispon√≠vel.

5. **Treinamento automatizado**  
   S√£o treinados modelos de machine learning, em seguido s√£o geradas m√©tricas como *AUC*, *sensibilidade/especificidade*, *F1-score*, *acur√°cia*, *ROC curves*, *confusion matrix* e *feature importances* para compara√ß√£o. A tela de treinamento exibe uma estimativa de tempo baseada no tamanho do dataset e nos modelos selecionados, ajudando a planejar execu√ß√µes mais pesadas.

6. **Resultados e download**  
   Relat√≥rios e modelos otimizados podem ser baixados junto dos valores dos hiperpar√¢metros de melhor desempenho.

7. **Interpreta√ß√£o via IA (opcional)**  
   Se o usu√°rio informar sua API Key, o **Google Gemini** fornece um resumo textual interpretando os achados cl√≠nicos dos modelos. A chave de API pode ser obtida gratuitamente em [Google AI Studio](https://aistudio.google.com/app/apikey)

---

## üé• Instructional Video

[![Watch the video](https://img.youtube.com/vi/_x5e5cBSl70/maxresdefault.jpg)](https://www.youtube.com/watch?v=_x5e5cBSl70)

Este tutorial em video demonstra:
- Introdu√ß√£o
- Fluxo de trabalho
- Como instalar o app localmente
- Como executar o programa e criar uma chave de API do Google
- Fazer upload do banco de dados
- Treinar e avaliar modelos de machine learning b√°sicos (KNN, SVM, Logistic Regression, etc)
- Interpretar os resultados explorando a curva ROC, m√©tricas e par√¢metros


---

## Running Locally (Windows)

**Pr√©-requisitos:**  
- Python 3.11 ou superior j√° instalado (verific√°vel com `python --version`)

**Passo-a-passo:**

1. **Baixe o reposit√≥rio**  
   - Acesse o bot√£o verde **"Code ‚Üí Download ZIP"** no GitHub  
   - Descompacte o arquivo em uma pasta de sua prefer√™ncia  

2. **Execute o Launcher**  
   - Dentro da pasta do projeto, localize o arquivo `launcher.py`  
   - Clique duas vezes nele
   - Ser√° aberto o launcher de instala√ß√£o, configura√ß√£o de API e execu√ß√£o
   - Este launcher deve permanecer aberto at√© a finaliza√ß√£o do programa  
   - Siga as instru√ß√µes que aparecerem na tela  

O launcher cria automaticamente o ambiente virtual, instala depend√™ncias do **FastAPI (backend)** e do **React (frontend)**, e inicia ambos os servi√ßos localmente:  
- Backend dispon√≠vel em `http://localhost:8000`  
- Interface (Frontend) em `http://localhost:3000`

Ent√£o abre o navegador ap√≥s 30 segundos dos servidores rodando j√° com a interface gr√°fica pronta para uso. Ap√≥s o uso do programa, o usu√°rio deve clicar em "End application" no laucher.

---

## Running Locally (Linux - Ubuntu or Windows Subsystem for Linux .:WSL.: )

O launcher tamb√©m roda em Ubuntu (ou derivados) desde que os requisitos abaixo estejam configurados.

**Pr√©-requisitos:**  
- Python 3.11 ou superior instalado (`python3 --version`)  
- Biblioteca Tkinter dispon√≠vel para o Python do sistema (`sudo apt update && sudo apt install python3-tk`)

**Passo-a-passo:**

1. **Baixe o reposit√≥rio**  
   Igual ao Windows: clique em **"Code ‚Üí Download ZIP"**, extraia o conte√∫do para uma pasta local.

2. **Execute o Launcher**  
   Abra um terminal na pasta extra√≠da, garanta que o ambiente gr√°fico esteja dispon√≠vel e execute:
   ```
   python3 launcher.py
   ```
   O launcher far√° a mesma automa√ß√£o do Windows (cria√ß√£o do ambiente virtual, instala√ß√£o das depend√™ncias do backend/frontend e abertura do navegador). Mantenha a janela aberta at√© finalizar e encerre pelo bot√£o ‚ÄúEnd application‚Äù ao terminar.


---

## Running in Google Colab (with LocalTunnel)

> [Em produ√ß√£o ‚Äî o link do Colab ser√° disponibilizado aqui, assim como o passo-a-passo futuramente.]
> *(Espa√ßo reservado para instru√ß√µes da execu√ß√£o n√£o-local (pelo Google Colab)*

---

## Details: Backend and Frontend Overview

- **Frontend (React + Vite)**  
  Respons√°vel pela intera√ß√£o do usu√°rio, upload do dataset, visualiza√ß√£o de gr√°ficos e resultados de modelagem.  

  Comando para desenvolvimento:
  ```
  npm run dev
  ```

- **Backend (FastAPI + scikit-learn)**  
  Camada anal√≠tica que executa a EDA, limpeza, e treinamento dos modelos.  
  Comando para execu√ß√£o isolada:
  ```
  uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
  ```

---

## Details: Environment Variables (.env.local)

√â necess√°rio um arquivo `.env.local` na raiz do projeto com os valores abaixo:

```
VITE_API_URL=http://localhost:8000/api
GEMINI_API_KEY=your-gemini-api-key
```

### Modelos avan√ßados (depend√™ncias extras)

O launcher j√° instala automaticamente `xgboost`, `lightgbm` e `catboost` a partir de `backend/requirements.txt`, ent√£o os boosters ficam habilitados por padr√£o. Se estiver rodando o backend sem o launcher (por exemplo, em um ambiente customizado), execute:
```
pip install xgboost lightgbm catboost
```

Caso essas bibliotecas n√£o estejam instaladas, o backend mostra uma mensagem no resultado do modelo e continua treinando os demais algoritmos normalmente.

- `VITE_API_URL`: endere√ßo do backend (local ou remoto)  
- `GEMINI_API_KEY`: chave gratuita obtida em [Google AI Studio](https://aistudio.google.com/app/apikey)

---

## Quickstart Recap

1. **Rodar o backend (local ou Colab)**  
2. **Garantir que est√° acess√≠vel** (`/docs` do FastAPI)  
3. **Configurar `VITE_API_URL` corretamente**  
4. **Rodar frontend (`npm run dev`)**  
5. **Fazer upload do dataset e seguir o pipeline**  
6. **Usar interpreta√ß√£o Gemini se desejado**

---

## Modelos dispon√≠veis para treinamento

- Logistic Regression  
- Elastic Net (Logistic Regression)  
- K-Nearest Neighbors (KNN)  
- Support Vector Machine (SVM) com presets Low/Medium/High  
- Random Forest  
- Gradient Boosting  
- XGBoost  
- LightGBM  
- CatBoost  
- Gaussian Naive Bayes  
- Voting Classifier (hard/soft, quando ‚â•2 modelos base treinados)  
- Stacking Classifier (Logistic Regression como meta-modelo)  
- K-Means Clustering (elbow + clusters)

---

<div align="center">
Feito com usando FastAPI, Vite e scikit-learn.  
Com apoio das APIs da Google AI e OpenAI Codex.
</div>
